{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "import demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_cleaning_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/gus/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"rslp\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"tweet_text\", \"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def stemming(texto: str) -> str:\n",
    "#     stemmer = nltk.stem.RSLPStemmer()\n",
    "#     palavras = []\n",
    "#     palavras = \" \".join([stemmer.stem(palavra) for palavra in texto.split()])\n",
    "#     return palavras\n",
    "\n",
    "# def lematization(texto: str) -> str:\n",
    "#     nlp = spacy.load(\"pt_core_news_sm\")\n",
    "#     doc = nlp(texto)\n",
    "#     texto = \" \".join([token.lemma_ for token in doc])\n",
    "#     return texto\n",
    "\n",
    "\n",
    "# def remover_stop_words(texto: str) -> str:\n",
    "#     stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "#     print(stopwords)\n",
    "#     texto = \" \".join(list(filter(lambda x: x not in stopwords, texto.split())))\n",
    "#     return texto\n",
    "\n",
    "\n",
    "# def formatar_texto(texto: str) -> str:\n",
    "#     texto = (\n",
    "#         re.sub(r\"(http\\S+)|(@\\w+)\", \"\", texto)  # remove links, usuários #\n",
    "#         .replace(\".\", \"\")\n",
    "#         .replace(\";\", \"\")\n",
    "#         .replace(\"—\", \"\")\n",
    "#     )\n",
    "\n",
    "#     texto = re.sub(r\"(  +)\", \" \", texto)  # remove espaços duplos\n",
    "#     texto = texto.lower().strip()\n",
    "\n",
    "#     return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura de dados brutos (~700k tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../data/raw/NoThemeTweets.csv\", delimiter = \",\", usecols = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de 150.000 tweets de forma pseudo aleatória para poupar custo computacional, as proporções de tweets positivos e negativos são mantidas.\n",
    "#### Essa será a nossa base de dados reduzida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.sample(150000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Checando as informações dos nossos dados com o metodo .info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção de textos duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.drop_duplicates([\"tweet_text\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação de funções para remover links, nomes de usuários dos tweets e caracteres especiais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"tweet_text\"] = df_raw[\"tweet_text\"].apply(\n",
    "    lambda tweet: formatar_texto(texto=tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"tweet_text\"] = df_raw[\"tweet_text\"].apply(\n",
    "    lambda tweet: remove_special_chars(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção dos emojis dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"tweet_text\"] = df_raw[\"tweet_text\"].apply(\n",
    "    lambda tweet: demoji.replace(tweet, \"\")); # custoso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação de função para etiquetar os sentimentos positivos com o valor 1 e negativos com o valor 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"sentiment\"] = df_raw[\"sentiment\"].replace({\"Positivo\": 1, \"Negativo\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando uma coluna com o número de palavras por tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.assign(\n",
    "    number_words=df_raw.tweet_text.apply(lambda x: len(x.split(\" \"))),\n",
    ")  # adiciona coluna com número de palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção dos tweets que possuem menos de 5 palavras. Esses tweets curtos podem vir a atrapalhar a etapa de modelagem e portanto serão excluídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_df_raw = df_raw.drop(\n",
    "    df_raw[df_raw.number_words < 5].index\n",
    ")  # remove tweets com menos de 5 palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remoção da coluna coluna number_words que não é mais necessária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_df_raw.drop([\"number_words\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_raw # liberando espaço na memória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2 - Geração de 4 DataFrames a partir da remoção ou não das Stopwords, e aplicação de Stemming ou Lematização. \n",
    "### DataFrame 1: sem Stopwords e Lematizado; \n",
    "### DataFrame 2 : sem Stopwords e com Stemming; \n",
    "### DataFrame 3: com Stopwords e Lematizado;\n",
    "### DataFrame 4: com Stopwords e com Stimming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Pipeline formatação de texto.png\" width=auto heigth=auto>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_steamed_no_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_steamed_no_stopwords[\"tweet_text\"] = df_no_stopwords[\"tweet_text\"].apply(\n",
    "    lambda tweet: stemming(texto=tweet)\n",
    ")\n",
    "\n",
    "df_lemmetized_no_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_lemmetized_no_stopwords[\"tweet_text\"] = df_no_stopwords[\"tweet_text\"].apply(\n",
    "    lambda tweet: lematization(tweet)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checagem do DataFrame lematizado sem a remoção das stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106869</th>\n",
       "      <td>af mas eu te amar tanto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156630</th>\n",
       "      <td>menina que ir passar um semana entristecir e e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440072</th>\n",
       "      <td>esse treta de o cube só mostrar mais ainda o q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373801</th>\n",
       "      <td>dormir demais né mas o dia passar voar mesmo n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44344</th>\n",
       "      <td>hoje meu sócio falar que descobrir um novo for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149059</th>\n",
       "      <td>mas eu não querer dormir   se não eu acordo ce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654378</th>\n",
       "      <td>my name is flora   sem ter outro flora aqui qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478001</th>\n",
       "      <td>um goleada para começar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272211</th>\n",
       "      <td>muito obrigado por o palavra anjinho   ah auhs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634135</th>\n",
       "      <td>eu amar o talento de o menino de o shinee juro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet_text  sentiment\n",
       "106869                            af mas eu te amar tanto          0\n",
       "156630  menina que ir passar um semana entristecir e e...          0\n",
       "440072  esse treta de o cube só mostrar mais ainda o q...          0\n",
       "373801  dormir demais né mas o dia passar voar mesmo n...          0\n",
       "44344   hoje meu sócio falar que descobrir um novo for...          1\n",
       "149059  mas eu não querer dormir   se não eu acordo ce...          0\n",
       "654378  my name is flora   sem ter outro flora aqui qu...          1\n",
       "478001                            um goleada para começar          1\n",
       "272211  muito obrigado por o palavra anjinho   ah auhs...          1\n",
       "634135  eu amar o talento de o menino de o shinee juro...          0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmetized_no_stopwords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checagem do DataFrame com stemming sem a remoção das stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106869</th>\n",
       "      <td>af mas eu te amo tant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156630</th>\n",
       "      <td>menin que vão pass uma seman entristec e em cl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440072</th>\n",
       "      <td>ess tret da cub só mostr mais aind o quant é d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373801</th>\n",
       "      <td>dorm demal né mas o dia pass vo mesm nem parec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44344</th>\n",
       "      <td>hoj meu sóci fal que descobr uma nov form de c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149059</th>\n",
       "      <td>mas eu não quer dorm se não eu acord ced e não...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654378</th>\n",
       "      <td>my nam is flor sem tem outr flor aqu que se ap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478001</th>\n",
       "      <td>uma gole par começ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272211</th>\n",
       "      <td>muit obrig pel palavr anj ah auhsuahsahsaushu ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634135</th>\n",
       "      <td>eu amo o talent do menin do shine jur pra voc ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet_text  sentiment\n",
       "106869                              af mas eu te amo tant          0\n",
       "156630  menin que vão pass uma seman entristec e em cl...          0\n",
       "440072  ess tret da cub só mostr mais aind o quant é d...          0\n",
       "373801  dorm demal né mas o dia pass vo mesm nem parec...          0\n",
       "44344   hoj meu sóci fal que descobr uma nov form de c...          1\n",
       "149059  mas eu não quer dorm se não eu acord ced e não...          0\n",
       "654378  my nam is flor sem tem outr flor aqu que se ap...          1\n",
       "478001                                 uma gole par começ          1\n",
       "272211  muit obrig pel palavr anj ah auhsuahsahsaushu ...          1\n",
       "634135  eu amo o talent do menin do shine jur pra voc ...          0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_steamed_no_stopwords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura das stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv(\"../data/no-theme-tweets/stopwords.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção das stopwords e aplicação de Lematização e stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_with_stopwords[\"tweet_text\"] = df_with_stopwords[\"tweet_text\"].apply(\n",
    "    lambda tweet: remover_stop_words(tweet, stopwords)\n",
    ")\n",
    "\n",
    "df_steamed_with_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_steamed_with_stopwords[\"tweet_text\"] = df_with_stopwords[\"tweet_text\"].apply(\n",
    "    lambda tweet: stemming(texto=tweet)\n",
    ")\n",
    "\n",
    "df_lemmetized_with_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_lemmetized_with_stopwords[\"tweet_text\"] = df_with_stopwords[\"tweet_text\"].apply(\n",
    "    lambda tweet: lematization(tweet)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checagem do DataFrame com stemming e com remoção das stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106869</th>\n",
       "      <td>af amo tant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156630</th>\n",
       "      <td>menin vão pass seman entristec clim desped</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440072</th>\n",
       "      <td>tret cub mostr aind quant difícil pra idol ass...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373801</th>\n",
       "      <td>dorm demal né dia pass vo parec 18h falt pra p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44344</th>\n",
       "      <td>hoj sóci fal descobr nov form comunic hardw vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149059</th>\n",
       "      <td>quer dorm acord ced consig madrug amanhã cas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654378</th>\n",
       "      <td>my nam is flor outr flor aqu apres agor cales ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478001</th>\n",
       "      <td>gole começ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272211</th>\n",
       "      <td>obrig palavr anj ah auhsuahsahsaushu val esper...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634135</th>\n",
       "      <td>amo talent menin shine jur pra q qualqu músic ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet_text  sentiment\n",
       "106869                                        af amo tant          0\n",
       "156630         menin vão pass seman entristec clim desped          0\n",
       "440072  tret cub mostr aind quant difícil pra idol ass...          0\n",
       "373801  dorm demal né dia pass vo parec 18h falt pra p...          0\n",
       "44344   hoj sóci fal descobr nov form comunic hardw vi...          1\n",
       "149059       quer dorm acord ced consig madrug amanhã cas          0\n",
       "654378  my nam is flor outr flor aqu apres agor cales ...          1\n",
       "478001                                         gole começ          1\n",
       "272211  obrig palavr anj ah auhsuahsahsaushu val esper...          1\n",
       "634135  amo talent menin shine jur pra q qualqu músic ...          0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_steamed_with_stopwords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checagem do dataframe lematizado e com remoção de stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106869</th>\n",
       "      <td>af amo tanto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156630</th>\n",
       "      <td>menina ir passar semana entristecir clima desp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440072</th>\n",
       "      <td>treta cube mostrar ainda quanto difícil pra id...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373801</th>\n",
       "      <td>dormir demais né dia passar voar parecer 18h f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44344</th>\n",
       "      <td>hoje sócio falar descobrir novo forma comunica...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149059</th>\n",
       "      <td>querer dormir acordo cedo consigo madrugar ama...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654378</th>\n",
       "      <td>my name is flora outro flora aqui apresente ag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478001</th>\n",
       "      <td>golear começar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272211</th>\n",
       "      <td>obrigado palavras anjinho ah auhsuahsahsaushua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634135</th>\n",
       "      <td>amo talento menino shinee juro pra q qualquer ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet_text  sentiment\n",
       "106869                                       af amo tanto          0\n",
       "156630  menina ir passar semana entristecir clima desp...          0\n",
       "440072  treta cube mostrar ainda quanto difícil pra id...          0\n",
       "373801  dormir demais né dia passar voar parecer 18h f...          0\n",
       "44344   hoje sócio falar descobrir novo forma comunica...          1\n",
       "149059  querer dormir acordo cedo consigo madrugar ama...          0\n",
       "654378  my name is flora outro flora aqui apresente ag...          1\n",
       "478001                                     golear começar          1\n",
       "272211  obrigado palavras anjinho ah auhsuahsahsaushua...          1\n",
       "634135  amo talento menino shinee juro pra q qualquer ...          0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmetized_with_stopwords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkagem da integridade do dados processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123681, 2) (123681, 2) (123681, 2) (123681, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_steamed_no_stopwords.shape,df_lemmetized_no_stopwords.shape,df_steamed_with_stopwords.shape,df_lemmetized_with_stopwords.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando os DataFrames na pasta data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steamed_no_stopwords.to_csv('../data/processed/df_steamed_no_stopwords.csv', index=False)\n",
    "df_lemmetized_no_stopwords.to_csv('../data/processed/df_lemmetized_no_stopwords.csv', index=False)\n",
    "df_steamed_with_stopwords.to_csv('../data/processed/df_steamed_with_stopwords.csv', index=False)\n",
    "df_lemmetized_with_stopwords.to_csv('../data/processed/df_lemmetized_with_stopwords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_lemmetized_no_stopwords.csv\t  df_steamed_no_stopwords.csv\n",
      "df_lemmetized_with_stopwords.csv  df_steamed_with_stopwords.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/processed/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "882c8c6501720d7339a894262ca6c76e47c685bc126574a2b14e77f6df77b0f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
